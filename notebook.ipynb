{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning (__process_data.py__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T07:16:18.562921Z",
     "start_time": "2023-08-03T07:16:18.557935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def load_data(messages_filepath, categories_filepath):\n",
    "    message_df = pd.read_csv(messages_filepath)\n",
    "    categories_df = pd.read_csv(categories_filepath)\n",
    "    merged_df = pd.merge(message_df, categories_df, how='inner', on='id')\n",
    "    return merged_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T07:16:05.701134Z",
     "start_time": "2023-08-03T07:16:05.697937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df['categories'] = df['categories'].str.split(';')\n",
    "    df['categories'] = df['categories'].apply(lambda x: dict(s.split('-') for s in x))\n",
    "    df = pd.concat([df, pd.json_normalize(df['categories'])], axis='columns')\n",
    "    df = df.drop(labels=['categories'], axis='columns')\n",
    "    return df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T07:16:05.987347Z",
     "start_time": "2023-08-03T07:16:05.981425Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def save_data(df, database_filepath):\n",
    "    engine = create_engine(f'sqlite:///{database_filepath}', echo=True)\n",
    "    conn = engine.connect()\n",
    "    table_name = 'DisasterMessage'\n",
    "    df.to_sql(table_name, conn, if_exists='fail')\n",
    "    conn.close()\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T07:16:06.597650Z",
     "start_time": "2023-08-03T07:16:06.595188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-03T07:16:23.211419Z",
     "start_time": "2023-08-03T07:16:22.186105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "    MESSAGES: data/disaster_messages.csv\n",
      "    CATEGORIES: data/disaster_categories.csv\n",
      "Cleaning data...\n",
      "Saving data...\n",
      "    DATABASE: data/DisasterResponse.db\n",
      "2023-08-03 10:16:22,634 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2023-08-03 10:16:22,641 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"DisasterMessage\")\n",
      "2023-08-03 10:16:22,642 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2023-08-03 10:16:22,642 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"DisasterMessage\")\n",
      "2023-08-03 10:16:22,642 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2023-08-03 10:16:22,644 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE \"DisasterMessage\" (\n",
      "\t\"index\" BIGINT, \n",
      "\tid BIGINT, \n",
      "\tmessage TEXT, \n",
      "\toriginal TEXT, \n",
      "\tgenre TEXT, \n",
      "\trelated TEXT, \n",
      "\trequest TEXT, \n",
      "\toffer TEXT, \n",
      "\taid_related TEXT, \n",
      "\tmedical_help TEXT, \n",
      "\tmedical_products TEXT, \n",
      "\tsearch_and_rescue TEXT, \n",
      "\tsecurity TEXT, \n",
      "\tmilitary TEXT, \n",
      "\tchild_alone TEXT, \n",
      "\twater TEXT, \n",
      "\tfood TEXT, \n",
      "\tshelter TEXT, \n",
      "\tclothing TEXT, \n",
      "\tmoney TEXT, \n",
      "\tmissing_people TEXT, \n",
      "\trefugees TEXT, \n",
      "\tdeath TEXT, \n",
      "\tother_aid TEXT, \n",
      "\tinfrastructure_related TEXT, \n",
      "\ttransport TEXT, \n",
      "\tbuildings TEXT, \n",
      "\telectricity TEXT, \n",
      "\ttools TEXT, \n",
      "\thospitals TEXT, \n",
      "\tshops TEXT, \n",
      "\taid_centers TEXT, \n",
      "\tother_infrastructure TEXT, \n",
      "\tweather_related TEXT, \n",
      "\tfloods TEXT, \n",
      "\tstorm TEXT, \n",
      "\tfire TEXT, \n",
      "\tearthquake TEXT, \n",
      "\tcold TEXT, \n",
      "\tother_weather TEXT, \n",
      "\tdirect_report TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2023-08-03 10:16:22,644 INFO sqlalchemy.engine.Engine [no key 0.00026s] ()\n",
      "2023-08-03 10:16:22,646 INFO sqlalchemy.engine.Engine CREATE INDEX \"ix_DisasterMessage_index\" ON \"DisasterMessage\" (\"index\")\n",
      "2023-08-03 10:16:22,646 INFO sqlalchemy.engine.Engine [no key 0.00029s] ()\n",
      "2023-08-03 10:16:23,100 INFO sqlalchemy.engine.Engine INSERT INTO \"DisasterMessage\" (\"index\", id, message, original, genre, related, request, offer, aid_related, medical_help, medical_products, search_and_rescue, security, military, child_alone, water, food, shelter, clothing, money, missing_people, refugees, death, other_aid, infrastructure_related, transport, buildings, electricity, tools, hospitals, shops, aid_centers, other_infrastructure, weather_related, floods, storm, fire, earthquake, cold, other_weather, direct_report) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2023-08-03 10:16:23,100 INFO sqlalchemy.engine.Engine [generated in 0.36703s] [(0, 2, 'Weather update - a cold front from Cuba that could pass over Haiti', 'Un front froid se retrouve sur Cuba ce matin. Il pourrait traverser Haiti demain. Des averses de pluie isolee sont encore prevues sur notre region ce soi', 'direct', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'), (1, 7, 'Is the Hurricane over or is it not over', 'Cyclone nan fini osinon li pa fini', 'direct', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0'), (2, 8, 'Looking for someone but no name', 'Patnm, di Maryani relem pou li banm nouvel li ak timoun yo. Mesi se john jean depi Monben kwochi.', 'direct', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'), (3, 9, 'UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.', 'UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.', 'direct', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'), (4, 12, 'says: west side of Haiti, rest of the country today and tonight', 'facade ouest d Haiti et le reste du pays aujourd hui et ce soir', 'direct', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'), (5, 14, 'Information about the National Palace-', 'Informtion au nivaux palais nationl', 'direct', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'), (6, 15, 'Storm at sacred heart of jesus', 'Cyclone Coeur sacr de jesus', 'direct', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0'), (7, 16, 'Please, we need tents and water. We are in Silo, Thank you!', 'Tanpri nou bezwen tant avek dlo nou zon silo mesi.', 'direct', '1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1')  ... displaying 10 of 26386 total bound parameter sets ...  (26384, 30264, 'Some 2,000 women protesting against the conduct of the elections were teargassed as they tried to converge on the local electoral commission offices in the southern oil city of Port Harcourt.', None, 'news', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'), (26385, 30265, 'A radical shift in thinking came about as a result of this meeting, recognizing that HIV/AIDS is at the core of the humanitarian crisis and identifying the crisis itself as a function of the HIV/AIDS pandemic.', None, 'news', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0')]\n",
      "2023-08-03 10:16:23,203 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2023-08-03 10:16:23,203 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2023-08-03 10:16:23,204 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_filepath = 'data/disaster_messages.csv'\n",
    "categories_filepath = 'data/disaster_categories.csv'\n",
    "database_filepath = 'data/DisasterResponse.db'\n",
    "print('Loading data...\\n    MESSAGES: {}\\n    CATEGORIES: {}'\n",
    "      .format(messages_filepath, categories_filepath))\n",
    "df = load_data(messages_filepath, categories_filepath)\n",
    "\n",
    "print('Cleaning data...')\n",
    "df = clean_data(df)\n",
    "\n",
    "print('Saving data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "save_data(df, database_filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning Pipeline (train_classifier.py)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohammedghawanni/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mohammedghawanni/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mohammedghawanni/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:43:13.055407Z",
     "start_time": "2023-08-05T09:43:13.036246Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "def load_data(database_filepath):\n",
    "    \"\"\"Loads the data from the specified database filepath.\n",
    "\n",
    "    Args:\n",
    "        database_filepath (str): The filepath of the database file.\n",
    "\n",
    "    Returns:\n",
    "        (list, list, list): The messages, categories, and category names.\n",
    "    \"\"\"\n",
    "\n",
    "    conn = create_engine(f'sqlite:///{database_filepath}').connect()\n",
    "    df = pd.read_sql_table('DisasterMessage', conn)\n",
    "    df = df.drop(labels=['index', 'id'], axis='columns')\n",
    "    messages = df.message.values\n",
    "    categories = df.iloc[:, 3:].values\n",
    "    category_names = df.iloc[:, 3:].columns\n",
    "    conn.close()\n",
    "    return messages, categories, category_names\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T08:19:53.114956Z",
     "start_time": "2023-08-05T08:19:53.112218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Tokenizes a text string and returns a list of clean tokens.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text string to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of clean tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    # get word tokens\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lemmatize every word (token) and remove whitespace and convert to lowercase\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "    return clean_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T08:19:53.497545Z",
     "start_time": "2023-08-05T08:19:53.492051Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"Builds a machine learning model for multi-label classification.\n",
    "\n",
    "    Returns:\n",
    "        GridSearchCV: A grid search object that can be used to fit the model.\n",
    "    \"\"\"\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [('features', FeatureUnion([\n",
    "            ('text_pipeline', Pipeline([\n",
    "                (\"vect\", CountVectorizer(tokenizer=tokenize)),\n",
    "                (\"tfidf\", TfidfTransformer())\n",
    "            ]))\n",
    "        ])),\n",
    "         ('clf', MultiOutputClassifier(RandomForestClassifier(random_state=2)))\n",
    "         ]\n",
    "    )\n",
    "\n",
    "    # Commented out some params to allow the code to run faster\n",
    "    parameters = {\n",
    "        # 'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        # 'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__estimator__n_estimators': [50],\n",
    "        # 'clf__min_samples_split': [2, 3, 4],\n",
    "        # 'clf__max_depth': [5, 10, 20]\n",
    "        # 'clf__max_depth': [5, 10]\n",
    "    }\n",
    "\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "    return cv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:28:34.645387Z",
     "start_time": "2023-08-05T09:28:34.638324Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test, category_names):\n",
    "    \"\"\"Evaluates a machine learning model on a test set.\n",
    "\n",
    "    Args:\n",
    "        model (sklearn.model): The machine learning model to evaluate.\n",
    "        X_test (numpy.ndarray): The test data.\n",
    "        Y_test (numpy.ndarray): The ground truth labels for the test data.\n",
    "        category_names (list): The names of the 36 categories.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # predict messages category\n",
    "    y_pred = model.predict(X_test)\n",
    "    Y_pred_df = pd.DataFrame(y_pred, columns=category_names)\n",
    "    # transform Y_test to df to loop over it\n",
    "    Y_test = pd.DataFrame().from_records(Y_test)\n",
    "\n",
    "    # loop over all categories and print classification_report for each category\n",
    "    for i in range(len(category_names)):\n",
    "        print('Category: {}'.format(category_names[i].upper()), \"\\n\\n\",\n",
    "              classification_report(Y_test.iloc[:, i], Y_pred_df.iloc[:, i]))\n",
    "\n",
    "    print(\"Best parameters: \", model.best_params_)\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:47:25.533207Z",
     "start_time": "2023-08-05T09:47:25.528104Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [],
   "source": [
    "def save_model(model, model_filepath):\n",
    "    \"\"\"Saves a machine learning model to a file.\n",
    "\n",
    "    Args:\n",
    "        model (sklearn.model): The machine learning model to save.\n",
    "        model_filepath (str): The filepath to the file where the model will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    pickle.dump(model, open(model_filepath, 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:28:35.580585Z",
     "start_time": "2023-08-05T09:28:35.576233Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "    DATABASE: data/DisasterResponse.db\n",
      "Building model...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved!\n"
     ]
    }
   ],
   "source": [
    "database_filepath = 'data/DisasterResponse.db'\n",
    "model_filepath = 'models/classifier.pkl'\n",
    "print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "X, Y, category_names = load_data(database_filepath)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print('Building model...')\n",
    "model = build_model()\n",
    "\n",
    "print('Training model...')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(model, model_filepath)\n",
    "\n",
    "print('Trained model saved!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:38:23.250735Z",
     "start_time": "2023-08-05T09:28:36.079290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "Category: RELATED \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.29      0.41      1188\n",
      "           1       0.82      0.97      0.89      4043\n",
      "           2       0.71      0.21      0.33        47\n",
      "\n",
      "    accuracy                           0.81      5278\n",
      "   macro avg       0.75      0.49      0.54      5278\n",
      "weighted avg       0.79      0.81      0.77      5278\n",
      "\n",
      "Category: REQUEST \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95      4431\n",
      "           1       0.90      0.45      0.60       847\n",
      "\n",
      "    accuracy                           0.90      5278\n",
      "   macro avg       0.90      0.72      0.77      5278\n",
      "weighted avg       0.90      0.90      0.89      5278\n",
      "\n",
      "Category: OFFER \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5254\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           1.00      5278\n",
      "   macro avg       0.50      0.50      0.50      5278\n",
      "weighted avg       0.99      1.00      0.99      5278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: AID_RELATED \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      3067\n",
      "           1       0.80      0.62      0.70      2211\n",
      "\n",
      "    accuracy                           0.77      5278\n",
      "   macro avg       0.78      0.75      0.76      5278\n",
      "weighted avg       0.78      0.77      0.77      5278\n",
      "\n",
      "Category: MEDICAL_HELP \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4875\n",
      "           1       0.67      0.07      0.13       403\n",
      "\n",
      "    accuracy                           0.93      5278\n",
      "   macro avg       0.80      0.54      0.55      5278\n",
      "weighted avg       0.91      0.93      0.90      5278\n",
      "\n",
      "Category: MEDICAL_PRODUCTS \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4997\n",
      "           1       0.90      0.06      0.12       281\n",
      "\n",
      "    accuracy                           0.95      5278\n",
      "   macro avg       0.92      0.53      0.55      5278\n",
      "weighted avg       0.95      0.95      0.93      5278\n",
      "\n",
      "Category: SEARCH_AND_RESCUE \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5132\n",
      "           1       0.50      0.01      0.03       146\n",
      "\n",
      "    accuracy                           0.97      5278\n",
      "   macro avg       0.74      0.51      0.51      5278\n",
      "weighted avg       0.96      0.97      0.96      5278\n",
      "\n",
      "Category: SECURITY \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5179\n",
      "           1       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.98      5278\n",
      "   macro avg       0.49      0.50      0.50      5278\n",
      "weighted avg       0.96      0.98      0.97      5278\n",
      "\n",
      "Category: MILITARY \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5092\n",
      "           1       0.81      0.07      0.13       186\n",
      "\n",
      "    accuracy                           0.97      5278\n",
      "   macro avg       0.89      0.53      0.56      5278\n",
      "weighted avg       0.96      0.97      0.95      5278\n",
      "\n",
      "Category: CHILD_ALONE \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5278\n",
      "\n",
      "    accuracy                           1.00      5278\n",
      "   macro avg       1.00      1.00      1.00      5278\n",
      "weighted avg       1.00      1.00      1.00      5278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: WATER \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4924\n",
      "           1       0.92      0.32      0.48       354\n",
      "\n",
      "    accuracy                           0.95      5278\n",
      "   macro avg       0.94      0.66      0.73      5278\n",
      "weighted avg       0.95      0.95      0.94      5278\n",
      "\n",
      "Category: FOOD \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      4663\n",
      "           1       0.89      0.37      0.52       615\n",
      "\n",
      "    accuracy                           0.92      5278\n",
      "   macro avg       0.90      0.68      0.74      5278\n",
      "weighted avg       0.92      0.92      0.91      5278\n",
      "\n",
      "Category: SHELTER \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4805\n",
      "           1       0.85      0.26      0.40       473\n",
      "\n",
      "    accuracy                           0.93      5278\n",
      "   macro avg       0.89      0.63      0.68      5278\n",
      "weighted avg       0.92      0.93      0.91      5278\n",
      "\n",
      "Category: CLOTHING \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5199\n",
      "           1       1.00      0.08      0.14        79\n",
      "\n",
      "    accuracy                           0.99      5278\n",
      "   macro avg       0.99      0.54      0.57      5278\n",
      "weighted avg       0.99      0.99      0.98      5278\n",
      "\n",
      "Category: MONEY \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5172\n",
      "           1       0.67      0.04      0.07       106\n",
      "\n",
      "    accuracy                           0.98      5278\n",
      "   macro avg       0.82      0.52      0.53      5278\n",
      "weighted avg       0.97      0.98      0.97      5278\n",
      "\n",
      "Category: MISSING_PEOPLE \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5209\n",
      "           1       1.00      0.01      0.03        69\n",
      "\n",
      "    accuracy                           0.99      5278\n",
      "   macro avg       0.99      0.51      0.51      5278\n",
      "weighted avg       0.99      0.99      0.98      5278\n",
      "\n",
      "Category: REFUGEES \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5100\n",
      "           1       0.60      0.02      0.03       178\n",
      "\n",
      "    accuracy                           0.97      5278\n",
      "   macro avg       0.78      0.51      0.51      5278\n",
      "weighted avg       0.95      0.97      0.95      5278\n",
      "\n",
      "Category: DEATH \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      5010\n",
      "           1       0.84      0.12      0.20       268\n",
      "\n",
      "    accuracy                           0.95      5278\n",
      "   macro avg       0.90      0.56      0.59      5278\n",
      "weighted avg       0.95      0.95      0.94      5278\n",
      "\n",
      "Category: OTHER_AID \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      4585\n",
      "           1       0.68      0.02      0.04       693\n",
      "\n",
      "    accuracy                           0.87      5278\n",
      "   macro avg       0.78      0.51      0.48      5278\n",
      "weighted avg       0.85      0.87      0.81      5278\n",
      "\n",
      "Category: INFRASTRUCTURE_RELATED \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4940\n",
      "           1       0.00      0.00      0.00       338\n",
      "\n",
      "    accuracy                           0.94      5278\n",
      "   macro avg       0.47      0.50      0.48      5278\n",
      "weighted avg       0.88      0.94      0.91      5278\n",
      "\n",
      "Category: TRANSPORT \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5039\n",
      "           1       0.80      0.07      0.12       239\n",
      "\n",
      "    accuracy                           0.96      5278\n",
      "   macro avg       0.88      0.53      0.55      5278\n",
      "weighted avg       0.95      0.96      0.94      5278\n",
      "\n",
      "Category: BUILDINGS \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      5012\n",
      "           1       0.82      0.09      0.16       266\n",
      "\n",
      "    accuracy                           0.95      5278\n",
      "   macro avg       0.89      0.54      0.57      5278\n",
      "weighted avg       0.95      0.95      0.93      5278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: ELECTRICITY \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5171\n",
      "           1       0.90      0.08      0.15       107\n",
      "\n",
      "    accuracy                           0.98      5278\n",
      "   macro avg       0.94      0.54      0.57      5278\n",
      "weighted avg       0.98      0.98      0.97      5278\n",
      "\n",
      "Category: TOOLS \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5254\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           1.00      5278\n",
      "   macro avg       0.50      0.50      0.50      5278\n",
      "weighted avg       0.99      1.00      0.99      5278\n",
      "\n",
      "Category: HOSPITALS \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5216\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.99      5278\n",
      "   macro avg       0.49      0.50      0.50      5278\n",
      "weighted avg       0.98      0.99      0.98      5278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: SHOPS \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5260\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           1.00      5278\n",
      "   macro avg       0.50      0.50      0.50      5278\n",
      "weighted avg       0.99      1.00      0.99      5278\n",
      "\n",
      "Category: AID_CENTERS \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5218\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.99      5278\n",
      "   macro avg       0.49      0.50      0.50      5278\n",
      "weighted avg       0.98      0.99      0.98      5278\n",
      "\n",
      "Category: OTHER_INFRASTRUCTURE \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5046\n",
      "           1       0.00      0.00      0.00       232\n",
      "\n",
      "    accuracy                           0.96      5278\n",
      "   macro avg       0.48      0.50      0.49      5278\n",
      "weighted avg       0.91      0.96      0.93      5278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: WEATHER_RELATED \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      3782\n",
      "           1       0.88      0.60      0.71      1496\n",
      "\n",
      "    accuracy                           0.86      5278\n",
      "   macro avg       0.87      0.78      0.81      5278\n",
      "weighted avg       0.86      0.86      0.85      5278\n",
      "\n",
      "Category: FLOODS \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4834\n",
      "           1       0.95      0.32      0.48       444\n",
      "\n",
      "    accuracy                           0.94      5278\n",
      "   macro avg       0.95      0.66      0.73      5278\n",
      "weighted avg       0.94      0.94      0.93      5278\n",
      "\n",
      "Category: STORM \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      4782\n",
      "           1       0.82      0.41      0.55       496\n",
      "\n",
      "    accuracy                           0.94      5278\n",
      "   macro avg       0.88      0.70      0.76      5278\n",
      "weighted avg       0.93      0.94      0.93      5278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohammedghawanni/.pyenv/versions/3.11/envs/udacity-project-disaster-recovery-pipeline/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: FIRE \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5219\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.99      5278\n",
      "   macro avg       0.49      0.50      0.50      5278\n",
      "weighted avg       0.98      0.99      0.98      5278\n",
      "\n",
      "Category: EARTHQUAKE \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4750\n",
      "           1       0.89      0.71      0.79       528\n",
      "\n",
      "    accuracy                           0.96      5278\n",
      "   macro avg       0.93      0.85      0.88      5278\n",
      "weighted avg       0.96      0.96      0.96      5278\n",
      "\n",
      "Category: COLD \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5172\n",
      "           1       0.67      0.04      0.07       106\n",
      "\n",
      "    accuracy                           0.98      5278\n",
      "   macro avg       0.82      0.52      0.53      5278\n",
      "weighted avg       0.97      0.98      0.97      5278\n",
      "\n",
      "Category: OTHER_WEATHER \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4987\n",
      "           1       0.57      0.03      0.05       291\n",
      "\n",
      "    accuracy                           0.95      5278\n",
      "   macro avg       0.76      0.51      0.51      5278\n",
      "weighted avg       0.93      0.95      0.92      5278\n",
      "\n",
      "Category: DIRECT_REPORT \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      4336\n",
      "           1       0.84      0.37      0.52       942\n",
      "\n",
      "    accuracy                           0.88      5278\n",
      "   macro avg       0.86      0.68      0.72      5278\n",
      "weighted avg       0.87      0.88      0.85      5278\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test, category_names)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:47:38.027092Z",
     "start_time": "2023-08-05T09:47:30.883394Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['1', '0', '0', ..., '0', '0', '0'],\n       ['1', '1', '0', ..., '0', '0', '1'],\n       ['1', '1', '0', ..., '0', '0', '0'],\n       ...,\n       ['1', '0', '0', ..., '0', '0', '0'],\n       ['1', '1', '0', ..., '0', '0', '0'],\n       ['1', '0', '0', ..., '0', '0', '0']], dtype=object)"
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(labels=['id']).iloc[:,1:3]\n",
    "Y_test\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:44:42.200549Z",
     "start_time": "2023-08-05T09:44:42.195157Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
